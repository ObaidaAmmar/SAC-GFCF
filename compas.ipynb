{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv2ee8LoLmSH"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zfHLoG5LmSI",
        "outputId": "aba301ec-dbd6-4937-d2b2-0adb5a79341f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import shap\n",
        "import torch\n",
        "from Explainer import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8iuDL0WLmSK"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SFkiM3_VLmSK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('Compas/Dataset/compas.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPZMVW0qLmSL"
      },
      "source": [
        "# Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJJGLmJKLmSL"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me_-3nY0LmSM"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-d6NUXgLmSM"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUrqjIjKLmSN"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "63N3pjaFHHxt"
      },
      "outputs": [],
      "source": [
        "data = data.dropna(subset=['c_jail_in', 'c_jail_out'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x_CSRHlsLmSO"
      },
      "outputs": [],
      "source": [
        "# filter similar to propublica\n",
        "data = data[\n",
        "    (data[\"days_b_screening_arrest\"] <= 30)\n",
        "    & (data[\"days_b_screening_arrest\"] >= -30)\n",
        "    & (data[\"is_recid\"] != -1)\n",
        "    & (data[\"c_charge_degree\"] != \"O\")\n",
        "    & (data[\"score_text\"] != \"N/A\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPpolPOPLmSO"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQlbL6POLmSP"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVnTdr63LmSP"
      },
      "source": [
        "#### Gender Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzVHPLauLmSQ"
      },
      "outputs": [],
      "source": [
        "gender_counts = data['sex'].value_counts()\n",
        "print(\"Gender distribution:\\n\", gender_counts)\n",
        "sns.countplot(x='sex', data=data)\n",
        "plt.title('Gender Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enRX8EdFLmSQ"
      },
      "source": [
        "#### Race Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVNZO8B8LmSR"
      },
      "outputs": [],
      "source": [
        "race_counts = data['race'].value_counts()\n",
        "print(\"Race distribution:\\n\", gender_counts)\n",
        "sns.countplot(x='race', data=data)\n",
        "plt.title('Race Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fEs25avoLmSR"
      },
      "outputs": [],
      "source": [
        "# select two largest groups\n",
        "data = data[(data[\"race\"] == \"African-American\") | (data[\"race\"] == \"Caucasian\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n3i_hQoKITBm"
      },
      "outputs": [],
      "source": [
        "data['length_of_stay'] = (pd.to_datetime(data['c_jail_out']) - pd.to_datetime(data['c_jail_in'])).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bKVnn4CiLmSS"
      },
      "outputs": [],
      "source": [
        "# select columns\n",
        "data = data[\n",
        "    [\n",
        "        \"sex\",\n",
        "        \"age\",\n",
        "        \"race\",\n",
        "        \"priors_count\",\n",
        "        \"length_of_stay\",\n",
        "        \"juv_fel_count\",\n",
        "        \"juv_misd_count\",\n",
        "        \"juv_other_count\",\n",
        "        \"two_year_recid\",\n",
        "    ]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FuFewjxeLmST"
      },
      "outputs": [],
      "source": [
        "# Encode Sex, Male = 0 / Female = 1\n",
        "data['sex'] = data['sex'].apply(lambda x: 0 if x == 'Male' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Uj0qI7hlLmST"
      },
      "outputs": [],
      "source": [
        "# Encode Race, African-American = 0 / Caucasian = 1\n",
        "data['race'] = data['race'].apply(lambda x: 0 if x == 'African-American' else 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnFDUpO5LmSU"
      },
      "source": [
        "# Split the Data into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xv7SrpU2LmSU"
      },
      "outputs": [],
      "source": [
        "# define X and y\n",
        "X = data.drop(\"two_year_recid\", axis=1)\n",
        "y = data[\"two_year_recid\"]\n",
        "\n",
        "# split the data in train-test sets; use random_state for reproducibility of the results\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIVh5aHcLmSV"
      },
      "outputs": [],
      "source": [
        "# inspect dataset\n",
        "display(X_train.head())\n",
        "\n",
        "# proportion of positives\n",
        "print(\"proportion of positives (train): %.2f\" % y_train.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EHigKkCpLmSV"
      },
      "outputs": [],
      "source": [
        "# fairlearn\n",
        "from fairlearn.metrics import (\n",
        "    false_positive_rate,\n",
        "    false_negative_rate,\n",
        "    true_positive_rate,\n",
        "    MetricFrame,\n",
        "    equalized_odds_difference,\n",
        "    demographic_parity_difference,\n",
        ")\n",
        "\n",
        "def score(\n",
        "    y_train,\n",
        "    y_train_pred,\n",
        "    y_test,\n",
        "    y_test_pred,\n",
        "    sensitive_features_train,\n",
        "    sensitive_features_test,\n",
        "    metrics={\"accuracy\": accuracy_score, \"fpr\": false_positive_rate, \"fnr\": false_negative_rate,},\n",
        "):\n",
        "    \"\"\"\n",
        "    Helper function to evaluate classifiers without too much repetition of code.\n",
        "    \"\"\"\n",
        "\n",
        "    # training set\n",
        "    mf_train = MetricFrame(\n",
        "        metrics=metrics,\n",
        "        y_true=y_train,\n",
        "        y_pred=y_train_pred,\n",
        "        sensitive_features=sensitive_features_train,\n",
        "    )\n",
        "\n",
        "    # test set\n",
        "    mf_test = MetricFrame(\n",
        "        metrics=metrics,\n",
        "        y_true=y_test,\n",
        "        y_pred=y_test_pred,\n",
        "        sensitive_features=sensitive_features_test,\n",
        "    )\n",
        "\n",
        "    # display results\n",
        "    display(\n",
        "        pd.concat(\n",
        "            [mf_train.by_group, mf_test.by_group], keys=[\"train\", \"test\"]\n",
        "        ).unstack(level=0)\n",
        "    )\n",
        "\n",
        "    # compute metrics\n",
        "    print(\n",
        "        \"equalized odds (test): %.2f\"\n",
        "        % equalized_odds_difference(\n",
        "            y_true=y_test,\n",
        "            y_pred=y_test_pred,\n",
        "            sensitive_features=sensitive_features_test,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(\"accuracy (test): %.2f\" % accuracy_score(y_true=y_test, y_pred=y_test_pred))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdmI_XWnLmSW"
      },
      "source": [
        "# Random Forest Calssifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ljcNlwEyLmSW"
      },
      "outputs": [],
      "source": [
        "naiveModel = RandomForestClassifier()\n",
        "naiveModel.fit(X_train,y_train)\n",
        "y_pred = naiveModel.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tMfXYBfPLmSW"
      },
      "outputs": [],
      "source": [
        "filename = 'random_forest_classifier.sav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPedYaMjLmSX"
      },
      "outputs": [],
      "source": [
        "naiveModel = pickle.load(open('Compas/Models/random_forest_classifier.sav', 'rb'))\n",
        "y_pred = naiveModel.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hshdM_xlLmSX"
      },
      "source": [
        "# Prediction Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQw89196LmSX"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)\n",
        "sns.heatmap(confusion, annot=True, fmt=\".2f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80TCVxJdLmSX"
      },
      "source": [
        "# Test Which Features are Influencing the Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "zXKcD1reLmSY",
        "outputId": "696ac28a-55f9-41e5-de8e-2192e194f61c"
      },
      "outputs": [],
      "source": [
        "shap_explainer = shap.Explainer(naiveModel)\n",
        "shap_values = shap_explainer.shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train, feature_names=data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4isBQAVLLmSY"
      },
      "source": [
        "# Test Model Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL96ET-XLmSY"
      },
      "outputs": [],
      "source": [
        "# score\n",
        "score(\n",
        "    y_train,\n",
        "    naiveModel.predict(X_train),\n",
        "    y_test,\n",
        "    naiveModel.predict(X_test),\n",
        "    X_train[\"race\"],\n",
        "    X_test[\"race\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhZa4YAhLmSZ"
      },
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdxB-oxlLmSZ"
      },
      "outputs": [],
      "source": [
        "#Save the trained model\n",
        "pickle.dump(naiveModel, open('Compas/Models/'+filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pqu1U0zLmSZ"
      },
      "source": [
        "# Bias Mitigation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8C0_hSB_tmx"
      },
      "source": [
        "#### Load Fair Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "q8WM1AP1_si5"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "file_name = 'fair_model.pkl'\n",
        "\n",
        "with open('Compas/Models/'+file_name, 'rb') as f:\n",
        "    fair_model2 = dill.load(f)\n",
        "\n",
        "y_pred_fair2 = fair_model2.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEgKw41JLmSZ"
      },
      "source": [
        "#### In Process Using Exponentiated Gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH974LMiLmSa",
        "outputId": "a114d92f-495f-4fd1-8986-5a04dcc94b56"
      },
      "outputs": [],
      "source": [
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
        "# train model\n",
        "fair_model = ExponentiatedGradient(\n",
        "    estimator= RandomForestClassifier(),\n",
        "    constraints= EqualizedOdds(),\n",
        "    eps=0.01,\n",
        ")\n",
        "fair_model.fit(X=X_train, y=y_train, sensitive_features=X_train[\"race\"])\n",
        "y_pred_fair = fair_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "4SwJ-OfmLmSb",
        "outputId": "1f3c58d8-74af-41b9-ea6f-92316aa9d330"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred_fair))\n",
        "confusion = confusion_matrix(y_test, y_pred_fair)\n",
        "print(confusion)\n",
        "sns.heatmap(confusion, annot=True, fmt=\".2f\")\n",
        "print(accuracy_score(y_test,y_pred_fair))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4fB3ByLmSc"
      },
      "source": [
        "# Test Fairness of New Fair Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "ZJ2AaVV0LmSc",
        "outputId": "4aaf867b-2b01-46df-a7bd-7d4b052f2b2c"
      },
      "outputs": [],
      "source": [
        "# score\n",
        "score(\n",
        "    y_train,\n",
        "    fair_model.predict(X_train, random_state=0),\n",
        "    y_test,\n",
        "    fair_model.predict(X_test, random_state=0),\n",
        "    X_train[\"race\"],\n",
        "    X_test[\"race\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J_e91nl_Uxj"
      },
      "source": [
        "# Save Fair Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(fair_model.sample_weight_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-pCa9Up7jv4",
        "outputId": "d656007c-98b5-40e7-d2ce-fdcfc3248e45"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "# Save the fair model\n",
        "filename = 'fair_model.pkl'\n",
        "\n",
        "dill.dump(fair_model, open('Compas/Models/'+file_name,'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAClFpLxLmSd"
      },
      "source": [
        "# Prepare the Affected Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYzvA_rTLmSd",
        "outputId": "c26c3518-f83f-4eb8-d3c0-50b7859e2394"
      },
      "outputs": [],
      "source": [
        "# Find instances where the model predicted target class 0\n",
        "predicted_target_1_instances = X_test[y_pred_fair == 1]\n",
        "print(predicted_target_1_instances['race'].value_counts())\n",
        "#africanAmerican = predicted_target_1_instances[predicted_target_1_instances['race'] == 0].sample(n=1, random_state=42)  # 42 is a random seed\n",
        "#caucasian = predicted_target_1_instances[predicted_target_1_instances['race'] == 1].sample(n=1, random_state=42)\n",
        "#filtered_test_data = pd.concat([africanAmerican, caucasian])\n",
        "#predicted_target_1_instances = filtered_test_data.sample(frac=1, random_state=42)\n",
        "\n",
        "# Save the filtered instances to a new dataset\n",
        "predicted_target_1_instances.to_csv('Compas/Dataset/predicted_target_1_instances.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7mQF7DJLmSe"
      },
      "source": [
        "# RL Agent Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kt0k6S3zLmSe",
        "outputId": "2cf0789f-d093-40a3-f015-21039b7d220e"
      },
      "outputs": [],
      "source": [
        "dataset = data\n",
        "affected_dataset = predicted_target_1_instances\n",
        "model = fair_model  #naiveModel\n",
        "target = 0\n",
        "protected_attribute = \"race\"\n",
        "features_to_change = [\"priors_count\", \"length_of_stay\"]\n",
        "number_of_counterfactuals = 5\n",
        "minimums = [0, 0] #[0, 1, 0]\n",
        "maximums = [38, 799]#[38, 10, 799]\n",
        "explainer = Explainer(dataset, affected_dataset, model, protected_attribute, features_to_change, number_of_counterfactuals, target, minimums, maximums, action_effectiveness=0.7)\n",
        "explainer.train()\n",
        "\n",
        "x, y = explainer.plot()\n",
        "plt.show()\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"Number of Timesteps\")\n",
        "plt.ylabel(\"Rewards\")\n",
        "plt.title(\"Learning Curve\" + \" Smoothed\")\n",
        "plt.show()\n",
        "\n",
        "cfs = explainer.report_counterfactuals()\n",
        "print(cfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PJxcNNC-pTIJ"
      },
      "outputs": [],
      "source": [
        "cfs_sorted = cfs.sort_values(by='Reward', ascending=False)\n",
        "cfs_sorted.to_csv('Compas/Fair CF/fair_cf_new.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Code-RL",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
